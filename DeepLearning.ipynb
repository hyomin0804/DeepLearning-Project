{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#라이브러리 작성\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, concatenate, Activation,Conv2DTranspose\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, History\n",
    "from keras import backend as keras\n",
    "from keras.utils.multi_gpu_utils import multi_gpu_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from keras import backend as K\n",
    "# import matplotlib.pyplot as plt\n",
    "from metrics import * # file\n",
    "from losses import * #file\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import r2_score\n",
    "# import cv2\n",
    "from keras.models import load_model\n",
    "import os\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "\n",
    "## img ##\n",
    "img_rows, img_cols = 1024,1024\n",
    "img_type = 'png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U-NET\n",
    "def get_unet(img_rows, img_cols):\n",
    "    inputs = Input((img_rows, img_cols,1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation=None, padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation=None, padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Activation('relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation=None, padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation=None, padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Activation('relu')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation=None, padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation=None, padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation=None, padding='same')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation=None, padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation=None, padding='same')(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation=None, padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation=None, padding='same')(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation=None, padding='same')(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Activation('relu')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation=None, padding='same')(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation=None, padding='same')(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation=None, padding='same')(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation=None, padding='same')(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Activation('relu')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation=None, padding='same')(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation=None, padding='same')(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Activation('relu')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 및 normalization\n",
    "    def load_train_data(train_npy_path, mask_npy_path):\n",
    "\n",
    "        print('-'*30)\n",
    "        print('%s data load...'%i)\n",
    "\n",
    "\n",
    "        print('-'*30)\n",
    "        print('load train images...')\n",
    "        print('-'*30)\n",
    "\n",
    "        imgs_train = np.load(train_npy_path)\n",
    "        imgs_mask_train = np.load(mask_npy_path)\n",
    "\n",
    "        imgs_train = imgs_train.astype('float32')\n",
    "        imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "        print('img : ', imgs_train.max())\n",
    "        print('mask : ',imgs_mask_train.max())\n",
    "\n",
    "        print('-'*30)\n",
    "        print('normalization start...')\n",
    "        print('-'*30)\n",
    "        imgs_train = imgs_train/255.0\n",
    "\n",
    "        imgs_mask_train[imgs_mask_train <= 127] = 0\n",
    "        imgs_mask_train[imgs_mask_train > 127] = 1\n",
    "\n",
    "        print('img : ',imgs_train.max())\n",
    "        print('mask : ',imgs_mask_train.max())\n",
    "\n",
    "        return imgs_train, imgs_mask_train\n",
    "\n",
    "    def load_test_data(test_npy_path):\n",
    "        print('-'*30)\n",
    "        print('load test images...')\n",
    "        print('-'*30)\n",
    "\n",
    "        imgs_test = np.load(test_npy_path)\n",
    "        imgs_test = imgs_test.astype('float32')\n",
    "        imgs_test /= 255\n",
    "\n",
    "        return imgs_test\n",
    "\n",
    "    def load_data(train_npy_path, mask_npy_path, test_npy_path):\n",
    "        imgs_train, imgs_mask_train = load_train_data(train_npy_path, mask_npy_path)\n",
    "        imgs_test = load_test_data(test_npy_path)\n",
    "        print(imgs_train.shape)\n",
    "        print(imgs_mask_train.shape)\n",
    "        print(imgs_test.shape)\n",
    "        return (imgs_train, imgs_mask_train, imgs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/gcubme4/Workspace/HM_LEE/spine_scoliosis/total_code'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir=./9th_data_aug/result/0/log --port=8895 --host=10.2.52.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    ## npy file #`#\n",
    "    npy_path = '../7th_total/data/%s/aug/npy/'%i\n",
    "\n",
    "    #학습저장 경로\n",
    "    check_model_path = '../7th_total/result/%s/check/'%i\n",
    "    model_path='../7th_total/result/%s/model/'%i\n",
    "    predict_path = '../7th_total/result/%s/npy/'%i\n",
    "    result_save_paths=\"../7th_total/result/%s/img/compare/\"%i\n",
    "    pred_img_path = '../7th_total/result/%s/img/mask/'%i\n",
    "    logdir=total_path+\"result/%s/log/\"%i + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "\n",
    "    imgs_train, imgs_mask_train, imgs_test = load_data(npy_path+'train_1024.npy', npy_path+'label_1024.npy', npy_path+'test_1024.npy')\n",
    "\n",
    "    \n",
    "    # multi-GPU\n",
    "\n",
    "    #학습 시작\n",
    "    print('-'*30)\n",
    "    print(\"load unet model\")\n",
    "    print('-'*30)\n",
    "    \n",
    "#     config = tf.compat.v1.ConfigProto()\n",
    "#     config.gpu_options.per_process_gpu_memory_fraction=0.8\n",
    "#     K.set_session(tf.compat.v1.Session(config=config))\n",
    "    \n",
    "    model = get_unet(img_rows, img_cols)\n",
    "\n",
    "    model = multi_gpu_model(model,gpus=2)\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='binary_crossentropy', metrics=[dice_coef_loss])\n",
    "    model_checkpoint = ModelCheckpoint(check_model_path+'check_11_8_%s.h5'%(i), monitor='loss',verbose=1, save_best_only=True, save_weights_only=False)\n",
    "#     model_checkpoint = ModelCheckpoint(check_model_path+'ckpt_{epoch:02d}.h5', monitor='loss',verbose=1, save_best_only=True)\n",
    "\n",
    "#     tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, update_freq='epoch')\n",
    "    \n",
    "#     es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "#     model.fit(imgs_train, imgs_mask_train, batch_size=6, epochs=150, verbose=1, validation_split=0.2, shuffle=True, callbacks=[es,model_checkpoint])\n",
    "\n",
    "    print('Fitting model...')\n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=2, epochs=5, verbose=1, validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "    \n",
    "    print('save model')\n",
    "    model.save(model_path+'model_11_8.h5')\n",
    "\n",
    "#     print('predict test data')\n",
    "#     imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "#     np.save(predict_path+'predict_11_8_%s.npy'%i, imgs_mask_test)\n",
    "    \n",
    "    \n",
    "    %matplotlib inline\n",
    "\n",
    "    fig, loss_ax = plt.subplots()\n",
    "\n",
    "    acc_ax = loss_ax.twinx()\n",
    "\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "    acc_ax.plot(hist.history['dice_coef_loss'], 'b', label='train dice_coef_loss')\n",
    "    acc_ax.plot(hist.history['val_dice_coef_loss'], 'g', label='val dice_coef_loss')\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('dice_coef_loss')\n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
