{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 1024, 1024, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 1024, 1024, 3 320         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 1024, 1024, 3 128         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 1024, 1024, 3 0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 1024, 1024, 3 9248        activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 1024, 1024, 3 128         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 1024, 1024, 3 0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 512, 512, 32) 0           activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 512, 512, 64) 18496       max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 512, 512, 64) 256         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 512, 512, 64) 0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 512, 512, 64) 36928       activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 512, 512, 64) 256         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 512, 512, 64) 0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling2D) (None, 256, 256, 64) 0           activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 256, 256, 128 73856       max_pooling2d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 256, 256, 128 512         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 256, 256, 128 0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 256, 256, 128 147584      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 256, 256, 128 512         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 256, 256, 128 0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling2D) (None, 128, 128, 128 0           activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 128, 128, 256 295168      max_pooling2d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 128, 128, 256 1024        conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 128, 128, 256 0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 128, 128, 256 590080      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 128, 128, 256 1024        conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 128, 128, 256 0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling2D) (None, 64, 64, 256)  0           activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 64, 64, 512)  1180160     max_pooling2d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 64, 64, 512)  2048        conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 64, 64, 512)  0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 64, 64, 512)  2359808     activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 64, 64, 512)  2048        conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 64, 64, 512)  0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_29 (Conv2DTran (None, 128, 128, 256 524544      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 128, 128, 512 0           conv2d_transpose_29[0][0]        \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 128, 128, 256 1179904     concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 128, 128, 256 1024        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 128, 128, 256 0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 128, 128, 256 590080      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 128, 128, 256 1024        conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 128, 128, 256 0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_30 (Conv2DTran (None, 256, 256, 128 131200      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 256, 256, 256 0           conv2d_transpose_30[0][0]        \n",
      "                                                                 activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 256, 256, 128 295040      concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 256, 256, 128 512         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 256, 256, 128 0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 256, 256, 128 147584      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 256, 256, 128 512         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 256, 256, 128 0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_31 (Conv2DTran (None, 512, 512, 64) 32832       activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 512, 512, 128 0           conv2d_transpose_31[0][0]        \n",
      "                                                                 activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 512, 512, 64) 73792       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 512, 512, 64) 256         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 512, 512, 64) 0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 512, 512, 64) 36928       activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 512, 512, 64) 256         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 512, 512, 64) 0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_32 (Conv2DTran (None, 1024, 1024, 3 8224        activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 1024, 1024, 6 0           conv2d_transpose_32[0][0]        \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 1024, 1024, 3 18464       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 1024, 1024, 3 128         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 1024, 1024, 3 0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 1024, 1024, 3 9248        activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 1024, 1024, 3 128         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 1024, 1024, 3 0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 1024, 1024, 1 33          activation_144[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 7,771,297\n",
      "Trainable params: 7,765,409\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = get_unet(img_rows, img_cols)\n",
    "# model.save('../exp.h5')\n",
    "model3=load_model('../exp.h5')\n",
    "model3.summary()\n",
    "\n",
    "\n",
    "# imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "# np.save(predict_path+'predict_exp_%s.npy'%i, imgs_mask_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측 데이터(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "0 data load...\n",
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(1955, 1024, 1024, 1)\n",
      "(1955, 1024, 1024, 1)\n",
      "(98, 1024, 1024, 1)\n",
      "98/98 [==============================] - 10s 103ms/step\n",
      "------------------------------\n",
      "1 data load...\n",
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(1955, 1024, 1024, 1)\n",
      "(1955, 1024, 1024, 1)\n",
      "(98, 1024, 1024, 1)\n",
      "98/98 [==============================] - 10s 102ms/step\n",
      "------------------------------\n",
      "2 data load...\n",
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(1955, 1024, 1024, 1)\n",
      "(1955, 1024, 1024, 1)\n",
      "(98, 1024, 1024, 1)\n",
      "98/98 [==============================] - 10s 98ms/step\n",
      "------------------------------\n",
      "3 data load...\n",
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(1955, 1024, 1024, 1)\n",
      "(1955, 1024, 1024, 1)\n",
      "(98, 1024, 1024, 1)\n",
      "98/98 [==============================] - 10s 104ms/step\n",
      "------------------------------\n",
      "4 data load...\n",
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "(1960, 1024, 1024, 1)\n",
      "(1960, 1024, 1024, 1)\n",
      "(97, 1024, 1024, 1)\n",
      "97/97 [==============================] - 10s 103ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    ## npy file #`#\n",
    "    npy_path = '../4th/data/%s/aug/npy/'%i\n",
    "    predict_path = '../4th/result/%s/npy/'%i\n",
    "        \n",
    "    imgs_train, imgs_mask_train, imgs_test = load_data(npy_path+'train_1024.npy', npy_path+'label_1024.npy', npy_path+'test_1024.npy')\n",
    "    imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "    np.save(predict_path+'predict_total_%s.npy'%i, imgs_mask_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측마스크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/gcubme4/Workspace/HM_LEE/spine_scoliosis/total_code'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for i in range(1):\n",
    "    pred_img_path = '../7th_total/result/%s/img/mask/'%i\n",
    "\n",
    "    pred_list=np.load('../7th_total/result/%s/npy/predict_exp_%s.npy'%(i,i))\n",
    "#     print(\"array to pred image\")\n",
    "    imgs = pred_list\n",
    "    for i in range(imgs.shape[0]):\n",
    "\n",
    "        img = imgs[i]\n",
    "        img[img <= 0.5] = 0\n",
    "        img[img > 0.5] = 255\n",
    "        \n",
    "        img_resize = cv2.resize(img, (1024,1024)) #resize\n",
    "        cv2.imwrite(pred_img_path +\"pred_%d.png\" %(i),img_resize)\n",
    "#         img = array_to_img(img)\n",
    "\n",
    "#         plt.imshow(img, cmap='gray')\n",
    "#         plt.axis('off')\n",
    "#         plt.show()\n",
    "#         img.save(pred_img_path +\"%d_pred.png\" %(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한부분씩 검사\n",
    "true_list=np.load('../../1st/data/4/aug/npy/test_label_1024_lat.npy') #test data mask\n",
    "true_list=true_list.astype('float32')\n",
    "true_list = true_list/255.0\n",
    "true_list[true_list > 0.5] = 1\n",
    "true_list[true_list <= 0.5] = 0\n",
    "print(true_list.shape)\n",
    "\n",
    "pred_list=np.load('../../1st/result/4/img/mask/crop/lat/lat.npy')\n",
    "pred_list[pred_list > 0.5] = 1\n",
    "pred_list[pred_list <= 0.5] = 0\n",
    "# pred_list[pred_list > 127] = 1\n",
    "# pred_list[pred_list <= 127] = 0\n",
    "\n",
    "sensitivity=[]\n",
    "specificity=[]\n",
    "acc=[]\n",
    "dsc=[]\n",
    "\n",
    "for i in range(len(true_list)):\n",
    "    yt=true_list[i].flatten()\n",
    "    yp=pred_list[i].flatten()\n",
    "    mat=confusion_matrix(yt,yp)\n",
    "    if len(mat) == 2:\n",
    "        ac=(mat[1,1]+mat[0,0])/(mat[1,0]+mat[1,1]+mat[0,1]+mat[0,0])\n",
    "        st=mat[1,1]/(mat[1,0]+mat[1,1])\n",
    "        sp=mat[0,0]/(mat[0,1]+mat[0,0])\n",
    "        if mat[1,0]+mat[1,1] == 0:\n",
    "            specificity.append(sp)\n",
    "            acc.append(ac)\n",
    "        else:\n",
    "            sensitivity.append(st)  \n",
    "            specificity.append(sp)\n",
    "            acc.append(ac)\n",
    "    else:\n",
    "        specificity.append(1)\n",
    "        acc.append(1)\n",
    "\n",
    "for i in range(len(true_list)):\n",
    "    yt=true_list[i]\n",
    "    yp=pred_list[i]\n",
    "    if np.sum(yt) != 0 and np.sum(yp) != 0:\n",
    "        dice = np.sum(yp[yt==1])*2.0 / (np.sum(yt) + np.sum(yp))\n",
    "        dsc.append(dice)\n",
    "\n",
    "        \n",
    "print(\"complete\")      \n",
    "print(\"sensitivity avg : {0:0.4f}\".format(np.mean(sensitivity)))\n",
    "std_sensitivity = np.std(sensitivity)\n",
    "print(\"sensitivity std : {0:0.4f}\".format(np.mean(std_sensitivity)))\n",
    "print(\"\")\n",
    "\n",
    "print(\"dsc avg : {0:0.4f}\".format(np.mean(dsc)))\n",
    "std_dsc = np.std(dsc)\n",
    "print(\"dsc std : {0:0.4f}\".format(np.mean(std_dsc)))\n",
    "print(\"\")\n",
    "\n",
    "# print(\"recall = \",recall)\n",
    "# print(\"f1score = \",f1score)\n",
    "# print(\"accuracy = \",acc)\n",
    "# print(\"auc = \",auc)\n",
    "# print(\"specificity avg : {0:0.4f}\".format(np.mean(specificity)))\n",
    "# std_specificity = np.std(specificity)\n",
    "# print(\"acc avg : {0:0.4f}\".format(np.mean(acc)))\n",
    "\n",
    "# print(\"sensitivity min:\",np.min(sensitivity))\n",
    "# print(\"specificity min:\",np.min(specificity))\n",
    "# print(\"dsc min:\",np.min(dsc))\n",
    "# print(\"acc min:\",np.min(acc))\n",
    "\n",
    "# print(\"sensitivity max:\",np.max(sensitivity))\n",
    "# print(\"specificity max:\",np.max(specificity))\n",
    "# print(\"dsc max:\",np.max(dsc))\n",
    "# print(\"acc max:\",np.max(acc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-folder 한번에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/gcubme4/Workspace/HM_LEE/spine_scoliosis/total_code'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "from metrics import *\n",
    "from losses import *\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import r2_score\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import os\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.compat.v1.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 윤지 검사 코드 (추가 평가지표 참고용)\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from data import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,roc_curve,auc\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "cv_cnt=0\n",
    "\n",
    "# for cv_cnt in range(2,5):\n",
    "mydata = dataProcess(512, 512)\n",
    "X_test,y_test=mydata.load_test_data(cv_cnt)\n",
    "\n",
    "print('-'*30)\n",
    "print('load model...')\n",
    "print('-'*30)\n",
    "\n",
    "model=load_model('../result/model/model_normalize_last(cv%s).h5'%str(cv_cnt))\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=1, verbose=1)\n",
    "#np.save('../result/%s/npy/test_pred_epoch300(cv%s).npy'%(str(cv_cnt), str(cv_cnt)), y_pred)\n",
    "# y_pred=np.load('../result/npy/test_pred(cv%s).npy'%cv_cnt)\n",
    "pred_label=[]\n",
    "sensitivity=[]\n",
    "specificity=[]\n",
    "\n",
    "f=open(\"../result/%s/txt/result(cv%s).txt\"%(str(cv_cnt),str(cv_cnt)),\"w\")\n",
    "pred_label=[]\n",
    "for i,v in enumerate(y_pred):\n",
    "    pre_ans=v.argmax()\n",
    "    pred_label.append(pre_ans)\n",
    "    txt= str(name_li[i][:7])+\",\"+str(name_li[i][8:9])+\",\"+str(y_test[i])+\",\"+\"N-{0:0.2f}\".format(v[0]*100)+\":\"+\"P-{0:0.2f}\".format(v[1]*100)+\",\"+str(pre_ans)+\"\\n\"\n",
    "    f.write(txt)\n",
    "f.close()\n",
    "\n",
    "\n",
    "cm=confusion_matrix(y_test,pred_label)\n",
    "print(cm)\n",
    "if len(cm) == 2:\n",
    "    st=cm[1,1]/(cm[1,0]+cm[1,1]) #TP/FN+TP\n",
    "    sp=cm[0,0]/(cm[0,1]+cm[0,0]) #TN/FP+TN\n",
    "    npv=cm[0,0]/(cm[0,0]+cm[1,0]) #TN/TN+FN\n",
    "    if cm[1,0]+cm[1,1] == 0:\n",
    "        specificity.append(sp)\n",
    "    else:\n",
    "        sensitivity.append(st)  \n",
    "        specificity.append(sp)\n",
    "        negativePvalue.append(npv)\n",
    "else:\n",
    "        specificity.append(1)\n",
    "        \n",
    "acc=accuracy_score(y_test,pred_label)\n",
    "precision=precision_score(y_test,pred_label)\n",
    "f1score=f1_score(y_test,pred_label)\n",
    "recall=recall_score(y_test,pred_label)\n",
    "fp,tp,_=roc_curve(y_test,y_pred[:,1])\n",
    "auc=auc(fp,tp)\n",
    "\n",
    "print('done')\n",
    "print(\"cv_cnt =======================\",cv_cnt)\n",
    "print(\"precision = \",precision)\n",
    "# print(\"recall = \",recall)\n",
    "print(\"sensitivity avg : {0:0.4f}\".format(np.mean(sensitivity)))\n",
    "print(\"specificity avg : {0:0.4f}\".format(np.mean(specificity)))\n",
    "print(\"negative predictable value avg : {0:0.4f}\".format(np.mean(negativePvalue)))\n",
    "print(\"f1score = \",f1score)\n",
    "print(\"accuracy = \",acc)\n",
    "print(\"auc = \",auc)\n",
    "\n",
    "\n",
    "f=open('../result/cv/result_cv{}.txt'.format(cv_cnt),\"w\")\n",
    "f.write('cv{} result\\n'.format(cv_cnt))\n",
    "f.write('=====================\\n')\n",
    "f.write(\"cm = {} \\n\".format(cm))\n",
    "f.write(\"sensitivity avg : {0:0.4f} \\n\".format(np.mean(sensitivity)))\n",
    "f.write(\"specificity avg : {0:0.4f} \\n\".format(np.mean(specificity)))\n",
    "f.write(\"negative predictable value avg : {0:0.4f} \\n\".format(np.mean(negativePvalue)))\n",
    "f.write(\"precision = {} \\n\".format(precision))\n",
    "# f.write(\"recall = {} \\n\".format(recall))\n",
    "f.write(\"f1score ={} \\n\".format(f1score))\n",
    "f.write(\"accuracy = {} \\n\".format(acc))\n",
    "f.write(\"auc = {} \\n\".format(auc))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째  (98, 1024, 1024, 1)\n",
      "\n",
      "precision avg : 0.9347\n",
      "precision std : 0.0000\n",
      "\n",
      "sensitivity avg : 0.9525\n",
      "sensitivity std : 0.0384\n",
      "\n",
      "dsc avg : 0.9589\n",
      "dsc std : 0.0251\n",
      "\n",
      "\n",
      "\n",
      "1번째  (98, 1024, 1024, 1)\n",
      "\n",
      "precision avg : 0.9371\n",
      "precision std : 0.0000\n",
      "\n",
      "sensitivity avg : 0.9617\n",
      "sensitivity std : 0.0239\n",
      "\n",
      "dsc avg : 0.9641\n",
      "dsc std : 0.0165\n",
      "\n",
      "\n",
      "\n",
      "2번째  (98, 1024, 1024, 1)\n",
      "\n",
      "precision avg : 0.9823\n",
      "precision std : 0.0000\n",
      "\n",
      "sensitivity avg : 0.9533\n",
      "sensitivity std : 0.0425\n",
      "\n",
      "dsc avg : 0.9585\n",
      "dsc std : 0.0281\n",
      "\n",
      "\n",
      "\n",
      "3번째  (98, 1024, 1024, 1)\n",
      "\n",
      "precision avg : 0.9769\n",
      "precision std : 0.0000\n",
      "\n",
      "sensitivity avg : 0.9630\n",
      "sensitivity std : 0.0266\n",
      "\n",
      "dsc avg : 0.9654\n",
      "dsc std : 0.0188\n",
      "\n",
      "\n",
      "\n",
      "4번째  (97, 1024, 1024, 1)\n",
      "\n",
      "precision avg : 0.9333\n",
      "precision std : 0.0000\n",
      "\n",
      "sensitivity avg : 0.9553\n",
      "sensitivity std : 0.0312\n",
      "\n",
      "dsc avg : 0.9608\n",
      "dsc std : 0.0210\n",
      "\n",
      "\n",
      "\n",
      "ALL PRE AVG: 0.9528\n",
      "ALL PRE STD: 0.0220\n"
     ]
    }
   ],
   "source": [
    "precision_all=[]\n",
    "\n",
    "for i in range(5):\n",
    "   \n",
    "    true_list=np.load('../4th/data/%s/aug/npy/test_label_1024.npy'%i) #test data mask\n",
    "    true_list=true_list.astype('float32')\n",
    "    true_list = true_list/255.0\n",
    "    true_list[true_list > 0.5] = 1\n",
    "    true_list[true_list <= 0.5] = 0\n",
    "    print(\"%d번째 \"%i,true_list.shape)\n",
    "    print(\"\")\n",
    "    pred_list=np.load('../4th/result/%s/npy/predict_total_%d.npy'%(i,i))\n",
    "    pred_list[pred_list > 0.5] = 1\n",
    "    pred_list[pred_list <= 0.5] = 0\n",
    "    # pred_list[pred_list > 127] = 1\n",
    "    # pred_list[pred_list <= 127] = 0\n",
    "    for i in range(len(true_list)):\n",
    "        yt=true_list[i].flatten()\n",
    "        yp=pred_list[i].flatten()\n",
    "            \n",
    "    precision=precision_score(yt,yp)\n",
    "    print(\"precision avg : {0:0.4f}\".format(np.mean(precision)))\n",
    "    std_precision = np.std(precision)\n",
    "    print(\"precision std : {0:0.4f}\".format(np.mean(std_precision)))\n",
    "    precision_all.append(np.mean(precision))\n",
    "    print(\"\")\n",
    "    ###############################################################################\n",
    "    sensitivity=[]\n",
    "    specificity=[]\n",
    "    acc=[]\n",
    "    dsc=[]\n",
    "\n",
    "    for i in range(len(true_list)):\n",
    "        yt=true_list[i].flatten()\n",
    "        yp=pred_list[i].flatten()\n",
    "        cm=confusion_matrix(yt,yp)\n",
    "        if len(mat) == 2:\n",
    "            ac=(cm[1,1]+cm[0,0])/(cm[1,0]+cm[1,1]+cm[0,1]+cm[0,0])            \n",
    "            st=cm[1,1]/(cm[1,0]+cm[1,1]) #TP/FN+TP\n",
    "            sp=cm[0,0]/(cm[0,1]+cm[0,0]) #TN/FP+TN\n",
    "            npv=cm[0,0]/(cm[0,0]+cm[1,0]) #TN/TN+FN\n",
    "            \n",
    "            if mat[1,0]+mat[1,1] == 0:\n",
    "                specificity.append(sp)\n",
    "                acc.append(ac)\n",
    "            else:\n",
    "                sensitivity.append(st)  \n",
    "                specificity.append(sp)\n",
    "                acc.append(ac)\n",
    "                negativePvalue.append(npv)\n",
    "        else:\n",
    "            specificity.append(1)\n",
    "            acc.append(1)\n",
    "\n",
    "    for i in range(len(true_list)):\n",
    "        yt=true_list[i]\n",
    "        yp=pred_list[i]\n",
    "        if np.sum(yt) != 0 and np.sum(yp) != 0:\n",
    "            dice = np.sum(yp[yt==1])*2.0 / (np.sum(yt) + np.sum(yp))\n",
    "            dsc.append(dice)\n",
    "    \n",
    "    print(\"sensitivity avg : {0:0.4f}\".format(np.mean(sensitivity)))\n",
    "    std_sensitivity = np.std(sensitivity)\n",
    "    print(\"sensitivity std : {0:0.4f}\".format(np.mean(std_sensitivity)))\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"dsc avg : {0:0.4f}\".format(np.mean(dsc)))\n",
    "    std_dsc = np.std(dsc)\n",
    "    print(\"dsc std : {0:0.4f}\".format(np.mean(std_dsc)))\n",
    "    print(\"\")\n",
    "    \n",
    "    print(\"negative predictable value avg : {0:0.4f}\".format(np.mean(negativePvalue)))\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    \n",
    "std_precision_all= np.std(precision_all)\n",
    "print(\"ALL PRE AVG: {0:0.4f}\".format(np.mean(precision_all)))\n",
    "print(\"ALL PRE STD: {0:0.4f}\".format(np.mean(std_precision_all)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원본+예측 마스크 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    pred_img_path = '../../1st/result/%d/img/mask/'%i\n",
    "    pred_list=np.load('../../1st/result/%d/npy/ap_exp%s.npy'%(i,i))\n",
    "                      \n",
    "    pred_list[pred_list > 0.5] = 1\n",
    "    pred_list[pred_list <= 0.5] = 0\n",
    "\n",
    "    if not os.path.isdir(pred_img_path):\n",
    "        os.makedirs(pred_img_path)\n",
    "        \n",
    "    pred_overlay_path = '../../1st/result/%d/img/overlay/'%i\n",
    "    if not os.path.isdir(pred_overlay_path):\n",
    "        os.makedirs(pred_overlay_path)\n",
    "\n",
    "    print(\"array to overlay image\")\n",
    "    imgs = pred_list\n",
    "    ori_path = glob.glob('../../1st/data/%d/non_aug/test_ori/' + '/*.png'%i)\n",
    "\n",
    "    for i in range(imgs.shape[0]):\n",
    "        img = imgs[i]\n",
    "        ori_imgs = load_img(ori_path[i])\n",
    "    #     ori_imgs = ori_imgs.resize((512,512))\n",
    "        ori_img = img_to_array(ori_imgs)\n",
    "        img_name = ori_path[i][ori_path[i].rindex('/')+1:ori_path[i].rindex('.')]\n",
    "        print(img_name)\n",
    "        img[img <= 0.5] = 0\n",
    "        img[img > 0.5] = 255\n",
    "        img = img_to_array(img)\n",
    "        ori_img[:,:,2] = img[:,:,0]\n",
    "        pred_img = array_to_img(ori_img)\n",
    "\n",
    "\n",
    "\n",
    "        plt.imshow(pred_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        #pred_img.save(pred_overlay_path+\"{}_pred.png\".format(img_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## result picture (원본 원본마스크 결과마스크 원본+예측마스크)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "bigpath=\"../4th/\"\n",
    "for i in range(3,4):\n",
    "    ori=glob.glob(bigpath+\"data/%d/non_aug/test_ori\"%i + '/*.png') #테스트.png 파일 경로\n",
    "    target=glob.glob(bigpath+\"data/%d/non_aug/test_msk\"%i + '/*.png')\n",
    "\n",
    "    pre=glob.glob(bigpath+\"result/%d/img/mask\"%i + '/*.png')\n",
    "    result_save_path=bigpath+\"result/%d/img/compare/\"%i\n",
    "\n",
    "    for a in range(len(ori)):\n",
    "\n",
    "        img_name = ori[a][ori[a].rindex('/')+1:ori[a].rindex('.')]\n",
    "        img1 = plt.imread(ori[a])\n",
    "        img2 = plt.imread(target[a])\n",
    "        img3 = plt.imread(pre[a])\n",
    "\n",
    "        img_name = ori[a][ori[a].rindex('/')+1:ori[a].rindex('.')]\n",
    "\n",
    "        img_back = cv2.imread(ori[a])\n",
    "        img_back2 = cv2.imread(ori[a])\n",
    "\n",
    "        img_color = cv2.imread(pre[a])\n",
    "\n",
    "        img_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY) #이미지의 색상공간 변경 1 channel\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(img_gray, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for cnt in contours:\n",
    "            test = cv2.drawContours(img_back, [cnt], 0, (255,0, 0,0), -1)\n",
    "\n",
    "        plt.rc('font', size=8)\n",
    "        plt.figure(figsize=(10,5),dpi=300)   \n",
    "        plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "        plt.subplot(1,4,1)\n",
    "        \n",
    "        plt.imshow(img1,cmap='gray')\n",
    "        plt.title('ori')\n",
    "\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,4,2)\n",
    "        plt.imshow(img2,cmap='gray')\n",
    "        plt.title('GT')\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,4,3)\n",
    "        plt.imshow(img3,cmap='gray')\n",
    "        plt.title('predict')\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1,4,4)\n",
    "        plt.imshow(test)\n",
    "        plt.imshow(img_back2,alpha=0.5)\n",
    "        plt.title('ori+predict')\n",
    "\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.savefig(result_save_path+\"{}_result.png\".format(img_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphology 크기정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2336e251c612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_img_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../../1st/result/0/img/mask/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mori_img_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../1st/data/0/non_aug/test_msk/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/*.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mori_img_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori_img_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "pred_img_path = \"../../1st/result/0/img/mask/\"\n",
    "ori_img_path=glob.glob(\"../../1st/data/0/non_aug/test_msk/\" + '/*.png')\n",
    "ori_img_path.sort()\n",
    "for i in range(3):\n",
    "    img1=plt.imread(ori_img_path[i])\n",
    "    img=pred_img_path +\"%d_pred.png\" %(i)\n",
    "    img = plt.imread(img)\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(img1,cmap='gray')\n",
    "    plt.title('GT')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    #침식3\n",
    "    kernel = np.ones((6,6), np.uint8)\n",
    "    result = cv2.erode(img, kernel, iterations = 1)\n",
    "    \n",
    "    #팽창3\n",
    "    kerne2 = np.ones((6,6), np.uint8)\n",
    "    result = cv2.dilate(result, kerne2, iterations = 1)\n",
    "\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.title('MO5')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    #침식4\n",
    "    kernel = np.ones((7,7), np.uint8)\n",
    "    result = cv2.erode(img, kernel, iterations = 1)\n",
    "    \n",
    "    #팽창4\n",
    "    kerne2 = np.ones((7,7), np.uint8)\n",
    "    result = cv2.dilate(result, kerne2, iterations = 1)\n",
    "    result=np.reshape(result,(1024,1024,1))\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(result,cmap='gray')\n",
    "    plt.title('MO6')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(5):\n",
    "    \n",
    "    npy_list=[]\n",
    "    \n",
    "    save_img_path = \"../../1st/result/%d/morphology/7/\"%a\n",
    "    pred_img_path=\"../../1st/result/%d/img/mask/\"%a\n",
    "    pred_npy_path=\"../../1st/result/%d/morphology/7/\"%a\n",
    "    ori_img_path=glob.glob(\"../../1st/data/%d/non_aug/test_msk/\"%a +'/*.png')\n",
    "    ori_img_path.sort()\n",
    "    \n",
    "    for i in range(len(ori_img_path)):\n",
    "        img_name = ori_img_path[i][ori_img_path[i].rindex('/')+1:ori_img_path[i].rindex('.')]\n",
    "\n",
    "        img=pred_img_path +\"%d_pred.png\" %(i)\n",
    "        img = plt.imread(img)\n",
    "\n",
    "        #침식3\n",
    "        kernel = np.ones((7,7), np.uint8)\n",
    "        result = cv2.erode(img, kernel, iterations = 1)\n",
    "\n",
    "        #팽창3\n",
    "        kerne2 = np.ones((7,7), np.uint8)\n",
    "        result2 = cv2.dilate(result, kerne2, iterations = 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        outer_result=np.reshape(result2,(1024,1024,1))\n",
    "        npy_list.append(outer_result)\n",
    "        print(outer_result.shape)\n",
    "        \n",
    "        outer_result=array_to_img(outer_result)\n",
    "        \n",
    "        \n",
    "        plt.imshow(outer_result, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "#         outer_result.save(save_img_path+\"%d_MO6.png\"%(i))\n",
    "\n",
    "    np.save(pred_npy_path+'%d_MO6.npy'%a, npy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다이콤 정보 엑셀로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "\n",
    "def collect_info(filename):\n",
    "    ds = pydicom.dcmread(filename)\n",
    "    Series=[]\n",
    "#     if ds.SeriesDescription not in Series:\n",
    "    info = []\n",
    "\n",
    "    info['PatientName']=ds.PatientName\n",
    "\n",
    "    info['SeriesDescription']=ds.SeriesDescription\n",
    "    Series.append(ds.SeriesDescription)\n",
    "    getRepetitionTime(ds)\n",
    "    getEchoTime(ds)\n",
    "    getInversionTime(ds)\n",
    "    getNumberOfAverages(ds)\n",
    "    getSpacingBetweenSlices(ds)\n",
    "    getPercentSampling(ds)\n",
    "    getPercentPhaseFieldOfView(ds)\n",
    "    getAcquisitionMatrix(ds)\n",
    "    getFlipAngle(ds)\n",
    "    getImagesInAcquisition(ds)\n",
    "    getPixelSpacing(ds)\n",
    "    f.write(info['PatientName'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['SeriesDescription'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['RepetitionTime'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['EchoTime'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['InversionTime'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['NumberOfAverages'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['SpacingBetweenSlices'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['PercentSampling'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['PercentPhaseFieldOfView'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['AcquisitionMatrix'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['FlipAngle'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['ImagesInAcquisition'])\n",
    "    f.write(\"\\t\")     \n",
    "    f.write(info['PixelSpacing'])\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n",
    "#     Series.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번 환자\n",
      "20181101\n",
      "BAEK JI WON\n",
      "20050923\n",
      "36008773\n",
      "13\n",
      "\n",
      "1 번 환자\n",
      "20181127\n",
      "YEO YEONG SEOK\n",
      "20030817\n",
      "27035443\n",
      "15\n",
      "\n",
      "2 번 환자\n",
      "20181208\n",
      "YOON KEON\n",
      "19990402\n",
      "13758133\n",
      "19\n",
      "\n",
      "3 번 환자\n",
      "20180822\n",
      "KIM KYEONG SOOK\n",
      "19431015\n",
      "16340723\n",
      "74\n",
      "\n",
      "4 번 환자\n",
      "20190102\n",
      "LEE SEONG AE\n",
      "19630920\n",
      "18910753\n",
      "55\n",
      "\n",
      "5 번 환자\n",
      "20190110\n",
      "PARK JOON YONG\n",
      "19700318\n",
      "21391713\n",
      "48\n",
      "\n",
      "6 번 환자\n",
      "20181019\n",
      "KANG SEONG HUI\n",
      "19301016\n",
      "22189653\n",
      "88\n",
      "\n",
      "7 번 환자\n",
      "20181211\n",
      "SA EUN JOO\n",
      "19810624\n",
      "24200553\n",
      "37\n",
      "\n",
      "8 번 환자\n",
      "20181214\n",
      "JUNG SOON YI\n",
      "19480427\n",
      "27880963\n",
      "70\n",
      "\n",
      "9 번 환자\n",
      "20181222\n",
      "MOON HYEONG JOO\n",
      "19470806\n",
      "29009953\n",
      "71\n",
      "\n",
      "10 번 환자\n",
      "20180713\n",
      "JANG SE JA^^^^\n",
      "19541207\n",
      "30278963\n",
      "63\n",
      "\n",
      "11 번 환자\n",
      "20181016\n",
      "MOON IN YEONG\n",
      "19371202\n",
      "30318663\n",
      "80\n",
      "\n",
      "12 번 환자\n",
      "20180714\n",
      "LIM CHOON JA\n",
      "19420625\n",
      "33970203\n",
      "76\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-66c2e45a3679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmy_List\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../TEST/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/*.dcm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_List\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mMetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcmread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_List\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStudyDate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPatientName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyomin/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mdcmread\u001b[0;34m(fp, defer_size, stop_before_pixels, force, specific_tags)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         dataset = read_partial(fp, stop_when, defer_size=defer_size,\n\u001b[0;32m--> 888\u001b[0;31m                                force=force, specific_tags=specific_tags)\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcaller_owns_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyomin/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(fileobj, stop_when, defer_size, force, specific_tags)\u001b[0m\n\u001b[1;32m    744\u001b[0m         dataset = read_dataset(fileobj, is_implicit_VR, is_little_endian,\n\u001b[1;32m    745\u001b[0m                                \u001b[0mstop_when\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_when\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefer_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                                specific_tags=specific_tags)\n\u001b[0m\u001b[1;32m    747\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menforce_valid_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyomin/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_dataset\u001b[0;34m(fp, is_implicit_VR, is_little_endian, bytelength, stop_when, defer_size, parent_encoding, specific_tags, at_top_level)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytelength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfp_start\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbytelength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mraw_data_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0;31m# Read data elements. Stop on some errors, but return what was read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hyomin/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mdata_element_generator\u001b[0;34m(fp, is_implicit_VR, is_little_endian, stop_when, defer_size, encoding, specific_tags)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_tell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 value = (fp_read(length) if length > 0\n\u001b[0m\u001b[1;32m    189\u001b[0m                          else empty_value_for_VR(VR, raw=True))\n\u001b[1;32m    190\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_List=glob.glob(\"../TEST/\"+'/*.dcm')\n",
    "for i in range(len(my_List)):\n",
    "    Metadata = pydicom.dcmread(my_List[i])\n",
    "    date = Metadata.StudyDate\n",
    "    name=Metadata.PatientName\n",
    "    birth=Metadata.PatientBirthDate\n",
    "    sex=Metadata.PatientSex\n",
    "    ID=Metadata.PatientID\n",
    "    age=Metadata.PatientAge\n",
    "    age=age[:-1]\n",
    "    age=int(age)\n",
    "#     Physician=Metadata.RequestingPhysician\n",
    "#     Institution=Metadata.InstitutionName\n",
    "#     Address=Metadata.InstitutionAddress\n",
    "#     PhysicianName=Metadata.ReferringPhysicianName\n",
    "#     StationName=Metadata.StationName\n",
    "    print(i,\"번 환자\")\n",
    "    print(date)\n",
    "    print(name)\n",
    "    print(birth)\n",
    "    print(ID)\n",
    "    print(age)\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not PersonName",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4076b81218fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#     getImagesInAcquisition(ds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#     getPixelSpacing(ds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PatientName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SeriesDescription'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not PersonName"
     ]
    }
   ],
   "source": [
    "    f = open(\"../TEST/list\", \"w\")\n",
    "    ds = pydicom.dcmread(my_List[0])\n",
    "    Series=[]\n",
    "#     if ds.SeriesDescription not in Series:\n",
    "    info = {}\n",
    "\n",
    "    info['PatientName']=ds.PatientName\n",
    "\n",
    "    info['SeriesDescription']=ds.SeriesDescription\n",
    "    Series.append(ds.SeriesDescription)\n",
    "    getRepetitionTime(ds)\n",
    "    getEchoTime(ds)\n",
    "    getInversionTime(ds)\n",
    "    getNumberOfAverages(ds)\n",
    "    getSpacingBetweenSlices(ds)\n",
    "    getPercentSampling(ds)\n",
    "    getPercentPhaseFieldOfView(ds)\n",
    "    getAcquisitionMatrix(ds)\n",
    "    getFlipAngle(ds)\n",
    "    getImagesInAcquisition(ds)\n",
    "    getPixelSpacing(ds)\n",
    "    f.write(info['PatientName'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['SeriesDescription'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['RepetitionTime'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['EchoTime'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['InversionTime'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['NumberOfAverages'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['SpacingBetweenSlices'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['PercentSampling'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['PercentPhaseFieldOfView'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['AcquisitionMatrix'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['FlipAngle'])\n",
    "    f.write(\"\\t\")\n",
    "    f.write(info['ImagesInAcquisition'])\n",
    "    f.write(\"\\t\")     \n",
    "    f.write(info['PixelSpacing'])\n",
    "    f.write(\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
